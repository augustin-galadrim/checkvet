components:
- layout_properties: {slot: editor_slot}
  name: text_editor_1
  properties: {}
  type: form:Components.TextEditor
- event_bindings: {x_save_clicked: report_footer_1_save_clicked, x_status_clicked: report_footer_1_status_clicked}
  layout_properties: {slot: bottom_buttons_slot}
  name: report_footer_1
  properties: {}
  type: form:Components.ReportFooter
- layout_properties: {slot: recorder_slot}
  name: recording_widget_1
  properties: {}
  type: form:Components.RecordingWidget
- data_bindings:
  - {code: 'self.item['''']', property: title, writeback: false}
  layout_properties: {slot: default}
  name: header_return_1
  properties: {return_form: Archives.ArchivesForm, title: ''}
  type: form:Components.HeaderReturn
container:
  properties:
    html: "<!DOCTYPE html>\n<html lang=\"fr\">\n<head>\n  <meta charset=\"UTF-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>Gestionnaire audio</title>\n  <style>\n    /* ===========================\n       Basic Layout & Container\n    ============================ */\n    * {\n      box-sizing: border-box;\n      font-family: Arial, sans-serif;\n      margin: 0;\n      padding: 0;\n    }\n    body {\n      background-color: #f5f5f5;\n      height: 100vh;\n      overflow: hidden;\n    }\n    .container {\n      display: flex;\n      flex-direction: column;\n      height: 100vh;\n      width: 100%;\n      max-width: 800px;\n      margin: 0 auto;\n      background: #fff;\n      box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n    }\n\n    /* ===========================\n       Scrollable Content\n    ============================ */\n    .scrollable-content {\n      flex: 1;\n      overflow-y: auto;\n      padding: 20px;\n      padding-bottom: 80px; /* space for bottom buttons */\n    }\n\n    /* ===========================\n       AUDIO SECTION\n    ============================ */\n    .audio-section {\n      background: #fff;\n      padding: 20px;\n      border-radius: 8px;\n      margin-bottom: 20px;\n      position: relative;\n    }\n\n    #audioBar {\n      width: 100%;\n      background-color: #4caf50;\n      color: #fff;\n      text-align: center;\n      padding: 15px;\n      font-size: 18px;\n      cursor: pointer;\n      margin-bottom: 20px;\n      border-radius: 5px;\n    }\n\n    .recording-controls {\n      position: relative;\n      width: 200px;\n      height: 200px;\n      margin: 20px auto;\n    }\n    .editor-component-container {\n      margin-top: 20px; /* Add some space between the audio section and the editor */\n    }\n    #circularProgress {\n      position: relative;\n      width: 200px;\n      height: 200px;\n    }\n    #progressRing {\n      position: absolute;\n      top: 0;\n      left: 0;\n      width: 100%;\n      height: 100%;\n      border-radius: 50%;\n      background: conic-gradient(#ddd 0deg, #ddd 0deg);\n    }\n    #centerHole {\n      position: absolute;\n      top: 8px;\n      left: 8px;\n      width: 184px;\n      height: 184px;\n      background: #fff;\n      border-radius: 50%;\n      z-index: 1;\n    }\n    .control-button-group {\n      position: absolute;\n      top: 50%;\n      left: 50%;\n      transform: translate(-50%, -50%);\n      display: flex;\n      gap: 30px;\n      z-index: 2;\n    }\n    .control-button {\n      width: 45px;\n      height: 45px;\n      border: 1px solid #666;\n      border-radius: 2px;\n      cursor: pointer;\n      background: #fff;\n      color: #666;\n      display: flex;\n      align-items: center;\n      justify-content: center;\n      font-size: 24px;\n      transition: all 0.3s ease;\n      padding: 0;\n    }\n    .control-button:hover {\n      background: #f5f5f5;\n      border-color: #333;\n      color: #333;\n    }\n\n    @keyframes recordingFlash {\n      0% { background: conic-gradient(#ffe5e5 0deg, #ffe5e5 360deg); }\n      50% { background: conic-gradient(#fff 0deg, #fff 360deg); }\n      100% { background: conic-gradient(#ffe5e5 0deg, #ffe5e5 360deg); }\n    }\n    .recording-flash {\n      animation: recordingFlash 1.5s infinite;\n    }\n\n    /* Hidden audio element */\n    #audioPlayback {\n      display: none;\n    }\n\n    /* ===========================\n       BOTTOM BUTTONS\n    ============================ */\n    .bottom-buttons {\n      position: fixed;\n      bottom: 0;\n      left: 50%;\n      transform: translateX(-50%);\n      width: 800px;\n      max-width: 100%;\n      background: #fff;\n      padding: 15px 20px;\n      display: flex;\n      justify-content: center;\n      gap: 20px;\n      border-top: 1px solid #ddd;\n      box-shadow: 0 -2px 4px rgba(0,0,0,0.1);\n      z-index: 10;\n    }\n    .bottom-button {\n      padding: 10px 30px;\n      border: 1px solid #ddd;\n      border-radius: 4px;\n      background: #fff;\n      cursor: pointer;\n      font-size: 14px;\n      transition: all 0.2s ease;\n    }\n    .bottom-button:hover {\n      background: #f5f5f5;\n      border-color: #999;\n    }\n\n    /* ===========================\n       NOTIFICATION BANNERS\n    ============================ */\n    #bannerContainer {\n      position: fixed;\n      top: 20px;\n      left: 50%;\n      transform: translateX(-50%);\n      z-index: 2000;\n    }\n    .banner {\n      margin-bottom: 10px;\n      padding: 10px 20px;\n      border-radius: 4px;\n      color: #fff;\n      opacity: 0.9;\n      font-size: 14px;\n      min-width: 200px;\n      text-align: center;\n      transition: opacity 0.3s ease;\n    }\n    .banner-success {\n      background-color: #4caf50;\n    }\n    .banner-error {\n      background-color: #f44336;\n    }\n  </style>\n</head>\n<body>\n  <div class=\"container\">\n    <div anvil-slot=\"default\"></div>\n\n    <!-- Main scrollable area -->\n    <div class=\"scrollable-content\">\n      <!-- AUDIO SECTION -->\n      <div class=\"audio-section\">\n        <div id=\"audioBar\">Dicter une modification</div>\n        <div class=\"recording-controls\">\n          <div anvil-slot=\"recorder_slot\"></div>\n        </div>\n        <!-- Hidden audio element -->\n        <audio id=\"audioPlayback\"></audio>\n      </div>\n      <div class=\"editor-component-container\">\n        <!-- 2. The anvil-slot is now *inside* this new container. -->\n        <!--    This is where you will drag and drop your EditorComponent. -->\n        <div anvil-slot=\"editor_slot\"></div>\n      </div>\n     \n    </div>\n    \n\n    <!-- Bottom buttons -->\n    <div anvil-slot=\"bottom_buttons_slot\"></div>\n  </div>\n\n  <!-- Banner container () -->\n  <div id=\"bannerContainer\"></div>\n\n  <!-- Optional PDF libs if needed -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js\"></script>\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js\"></script>\n\n  <script>\n    /****************************************************\n     * 1) GLOBALS & HELPER FUNCTIONS\n     *    - We keep the function NAMES the same as your .py calls: \n     *      \"getEditorContent\", \"setEditorContent\", \"displayBanner\"\n     ****************************************************/\n    console.log(\"===== LOADING HYBRID  HTML/JS FOR AudioManagerEdit =====\");\n\n    // We'll store all \"\" stuff in a single object to avoid collisions\n    if (!window.__my_audio_manager_globals_) {\n      window.__my_audio_manager_globals_ = true;\n\n      // Basic state\n      window.audioManagerData = {\n        mediaRecorder: null,\n        recordedChunks: [],\n        audioBlob: null,\n        stream: null,\n        isRecording: false\n      };\n      window.transcriptionProgressData = {\n        currentProgress: 0,\n        intervalId: null\n      };\n\n      /***********************************************\n       * Banner function (matching .py calls: displayBanner)\n       ***********************************************/\n      window.displayBanner = function(message, type) {\n        console.log(\"displayBanner() =>\", message, type);\n        const container = document.getElementById(\"bannerContainer\");\n        if (!container) {\n          console.warn(\"#bannerContainer not found!\");\n          return;\n        }\n        const banner = document.createElement(\"div\");\n        banner.className = \"banner \" + (type === \"success\" ? \"banner-success\" : \"banner-error\");\n        banner.textContent = message;\n        container.appendChild(banner);\n\n        // Auto-hide after 3s\n        setTimeout(() => {\n          banner.style.opacity = \"0\";\n          setTimeout(() => {\n            if (banner.parentNode) {\n              banner.parentNode.removeChild(banner);\n            }\n          }, 300);\n        }, 3000);\n      };\n\n\n      /***********************************************\n       * Additional \"\" Helper Functions\n       ***********************************************/\n      // blob -> base64\n      window.blobToBase64 = function(blob) {\n        return new Promise((resolve, reject) => {\n          const reader = new FileReader();\n          reader.onloadend = () => {\n            const base64 = reader.result.split(\",\")[1];\n            resolve(base64);\n          };\n          reader.onerror = reject;\n          reader.readAsDataURL(blob);\n        });\n      };\n\n      // Simulate transcription progress\n      window.setRingPercentage = function(percentage) {\n        const ringElem = document.getElementById(\"progressRing\");\n        if (!ringElem) return;\n        const clamped = Math.max(0, Math.min(percentage, 100));\n        const angle = (clamped / 100) * 360;\n        ringElem.style.background = `conic-gradient(#4caf50 ${angle}deg, #ddd ${angle}deg)`;\n      };\n\n      window.simulateTranscriptionProgress = function() {\n        const data = window.transcriptionProgressData;\n        data.currentProgress = 0;\n        window.setRingPercentage(0);\n        data.intervalId = setInterval(() => {\n          if (data.currentProgress < 90) {\n            data.currentProgress += 2;\n            window.setRingPercentage(data.currentProgress);\n          } else {\n            clearInterval(data.intervalId);\n          }\n        }, 300);\n      };\n\n      window.finishTranscriptionProgress = function() {\n        const data = window.transcriptionProgressData;\n        clearInterval(data.intervalId);\n        data.currentProgress = 100;\n        window.setRingPercentage(100);\n      };\n\n      window.startRecordingFlash = function() {\n        const ringElem = document.getElementById(\"progressRing\");\n        if (ringElem) ringElem.classList.add(\"recording-flash\");\n      };\n\n      window.stopRecordingFlash = function() {\n        const ringElem = document.getElementById(\"progressRing\");\n        if (ringElem) ringElem.classList.remove(\"recording-flash\");\n      };\n\n      // Process the recording\n      window.processRecording = async function(blob) {\n        console.log(\"processRecording => start\");\n        try {\n          window.simulateTranscriptionProgress();\n          const base64Audio = await window.blobToBase64(blob);\n          // We call the python method \"process_recording\"\n          const stopBtn = document.getElementById(\"stopButton\");\n          if (!stopBtn) {\n            console.warn(\"stopButton not found => can't call process_recording in python\");\n            return;\n          }\n          anvil.call(stopBtn, \"process_recording\", base64Audio)\n            .then(result => {\n              console.log(\"process_recording responded =>\", result);\n              window.finishTranscriptionProgress();\n              window.audioManagerData.audioBlob = blob;\n              window.lastAudioBlob = blob;\n            })\n            .catch(error => {\n              console.error(\"Error in process_recording =>\", error);\n              alert(\"Erreur lors du traitement de l'enregistrement ().\");\n              window.finishTranscriptionProgress();\n            });\n        } catch (error) {\n          console.error(\"Exception in processRecording =>\", error);\n          alert(\"Erreur lors de la conversion du blob en base64 ().\");\n          window.finishTranscriptionProgress();\n        }\n      };\n\n      // (Optional) Export PDF\n      window.exportToPDF = function(event) {\n        let content = window.getEditorContent();\n        let images = [];\n        document.querySelectorAll(\"#editor img\").forEach(img => {\n          images.push({\n            media: img.src,\n            reference_id: img.dataset.referenceId || (\"img_\" + Date.now()),\n            position: img.offsetTop.toString()\n          });\n        });\n        let placeholders = { bodyContent: content };\n        let fileName = prompt(\"Veuillez entrer un nom de fichier pour le PDF ():\");\n        if (!fileName || fileName.trim() === \"\") {\n          alert(\"Exportation du PDF annulée.\");\n          return;\n        }\n        anvil.call(event, \"build_report_pdf_relay\", placeholders, images)\n          .then(pdfBase64 => {\n            let pdfUrl = \"data:application/pdf;base64,\" + pdfBase64;\n            window.open(pdfUrl, \"_blank\");\n          })\n          .catch(error => {\n            console.error(\"Erreur lors de la génération du PDF:\", error);\n            alert(\"Erreur PDF: \" + error.message);\n          });\n      };\n    }\n\n    /****************************************************\n     * 2) ATTACH EVENT LISTENERS\n     ****************************************************/\n    window.__attachAudioManagerEvents = function() {\n      console.log(\"===== Attaching  Event Listeners Now =====\");\n      const data = window.audioManagerData;\n\n      // \"Retour\" bar\n      const retourBar = document.getElementById(\"retourBar\");\n      if (retourBar) {\n        retourBar.replaceWith(retourBar.cloneNode(true));\n        const newRetourBar = document.getElementById(\"retourBar\");\n        newRetourBar.addEventListener(\"click\", e => {\n          console.log(\"[] 'Retour' clicked => call retour_clicked in Python\");\n          anvil.call(e.target, \"retour_clicked\");\n        });\n      }\n\n      // \"Relancer l'IA\" banner\n      const audioBar = document.getElementById(\"audioBar\");\n      if (audioBar) {\n        audioBar.replaceWith(audioBar.cloneNode(true));\n        const newAudioBar = document.getElementById(\"audioBar\");\n        newAudioBar.addEventListener(\"click\", e => {\n          console.log(\"[] 'audioBar' clicked => call relaunch_ai in Python\");\n          anvil.call(e.target, \"relaunch_ai\");\n        });\n      }\n\n      // Start/Pause button\n      const playButton = document.getElementById(\"playButton\");\n      if (playButton) {\n        playButton.replaceWith(playButton.cloneNode(true));\n      }\n      const newPlayButton = document.getElementById(\"playButton\");\n\n      // Stop button\n      const stopButton = document.getElementById(\"stopButton\");\n      if (stopButton) {\n        stopButton.replaceWith(stopButton.cloneNode(true));\n      }\n      const newStopButton = document.getElementById(\"stopButton\");\n\n      // Our icons\n      window.micIconHTML = `\n        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"20\" height=\"20\" fill=\"currentColor\" viewBox=\"0 0 16 16\">\n          <path d=\"M8 11.5a2.5 2.5 0 0 0 2.5-2.5V4a2.5 2.5 0 1 0-5 0v5A2.5 2.5 0 0 0 8 11.5z\"/>\n          <path d=\"M10 5a.5.5 0 0 1 1 0v4a3 3 0 1 1-6 0V5a.5.5 0 0 1 1 0v4a2 2 0 0 0 4 0V5z\"/>\n          <path d=\"M8 13a4.5 4.5 0 0 0 4.5-4.5.5.5 0 0 1 1 0 5.5 5.5 0 0 1-11 0 .5.5 0 0 1 1 0A4.5 4.5 0 0 0 8 13z\"/>\n        </svg>\n      `;\n      window.pauseIconHTML = `\n        <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"16\" height=\"16\">\n          <rect x=\"9\" y=\"2\" width=\"6\" height=\"12\" rx=\"3\" fill=\"currentColor\"/>\n          <path d=\"M6 12a6 6 0 0 0 12 0M12 18v4M8 22h8\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\"/>\n        </svg>\n      `;\n\n      // Start/Pause logic\n      if (newPlayButton) {\n        newPlayButton.addEventListener(\"click\", async evt => {\n          console.log(\"playButton clicked => isRecording?\", data.isRecording);\n          if (!data.isRecording) {\n            // Start\n            if (data.mediaRecorder && data.mediaRecorder.state === \"inactive\") {\n              data.mediaRecorder = null;\n            }\n            if (!data.mediaRecorder) {\n              try {\n                data.stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n                data.mediaRecorder = new MediaRecorder(data.stream);\n                data.recordedChunks = [];\n                data.mediaRecorder.ondataavailable = ev => data.recordedChunks.push(ev.data);\n                data.mediaRecorder.start();\n                data.isRecording = true;\n                newPlayButton.innerHTML = window.pauseIconHTML;\n                anvil.call(evt.target, \"start_recording\");\n                window.startRecordingFlash();\n              } catch (err) {\n                console.error(\"Erreur micro:\", err);\n                anvil.call(evt.target, \"show_error\", \"Accès micro refusé / indisponible.\");\n              }\n            } else if (data.mediaRecorder.state === \"paused\") {\n              data.mediaRecorder.resume();\n              data.isRecording = true;\n              newPlayButton.innerHTML = window.pauseIconHTML;\n              anvil.call(evt.target, \"start_recording\");\n            }\n          } else {\n            // Pause\n            if (data.mediaRecorder && data.mediaRecorder.state === \"recording\") {\n              data.mediaRecorder.pause();\n              data.isRecording = false;\n              newPlayButton.innerHTML = window.micIconHTML;\n              anvil.call(evt.target, \"pause_recording\");\n            }\n          }\n        });\n      }\n\n      // Stop logic\n      if (newStopButton) {\n        newStopButton.addEventListener(\"click\", evt => {\n          if (data.mediaRecorder && data.mediaRecorder.state !== \"inactive\") {\n            data.mediaRecorder.onstop = () => {\n              data.audioBlob = new Blob(data.recordedChunks, { type: \"audio/webm\" });\n              const audioPlayback = document.getElementById(\"audioPlayback\");\n              if (audioPlayback) {\n                const audioURL = URL.createObjectURL(data.audioBlob);\n                audioPlayback.src = audioURL;\n                audioPlayback.load();\n              }\n              window.processRecording(data.audioBlob);\n              anvil.call(evt.target, \"stop_recording\");\n              window.stopRecordingFlash();\n            };\n            data.mediaRecorder.stop();\n            data.isRecording = false;\n            if (newPlayButton) newPlayButton.innerHTML = window.micIconHTML;\n          }\n        });\n      }\n\n      // Bottom buttons (Statut, Archiver, Partager)\n      const bottomButtons = document.querySelectorAll(\".bottom-button\");\n      bottomButtons.forEach(btn => {\n        btn.removeEventListener(\"click\", btn.__listener);\n        const newListener = function(e) {\n          const action = e.currentTarget.dataset.click;\n          console.log(\"[] bottom-button =>\", action);\n          if (action === \"statut\") {\n            anvil.call(e.currentTarget, \"on_statut_clicked\").then(chosenStatut => {\n              if (chosenStatut) {\n                e.currentTarget.textContent = chosenStatut;\n              }\n            });\n          } else if (action === \"update\") {\n            // \"Archiver\"\n            console.log(\"Archiver => calling update_report in Python\");\n            const contentJSON = JSON.stringify({ content: window.getEditorContent() });\n            const images = Array.from(document.querySelectorAll(\"#editor img\")).map(img => ({\n              media: img.src,\n              reference_id: img.dataset.referenceId || (\"img_\" + Date.now()),\n              position: img.offsetTop.toString()\n            }));\n            anvil.call(e.currentTarget, \"update_report\", e.currentTarget.textContent, contentJSON, images);\n          } else if (action === \"partager\") {\n            // currently just show a banner\n            displayBanner(\"fonctionnalité en cours de développement ()\", \"success\");\n          }\n        };\n        btn.__listener = newListener;\n        btn.addEventListener(\"click\", newListener);\n      });\n\n      console.log(\"===== Done attaching event listeners () =====\");\n    };\n\n    /****************************************************\n     * 3) INIT ON LOAD\n     ****************************************************/\n    console.log(\"Calling __attachAudioManagerEvents() now...\");\n    window.__attachAudioManagerEvents();\n\n    // Refresh session on visibility changes\n    if (!window.__session_handlers_initialized_) {\n      window.__session_handlers_initialized_ = true;\n      document.addEventListener(\"visibilitychange\", () => {\n        if (document.visibilityState === \"visible\") {\n          anvil.call(document.body, \"refresh_session_relay\");\n        }\n      });\n      window.addEventListener(\"online\", () => {\n        anvil.call(document.body, \"refresh_session_relay\");\n      });\n    }\n    console.log(\"===== HYBRID  HTML/JS FULLY LOADED =====\");\n  </script>\n</body>\n</html>\n"
  type: HtmlTemplate
is_package: true
