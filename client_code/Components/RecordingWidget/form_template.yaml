components: []
container:
  properties:
    html: |-
      <div class="audio-section">
        <div class="recording-controls" id="recordingMode">
          <button id="recordingWidget-button-toggle" title="Start Recording">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" viewBox="0 0 16 16">
              <path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z"/>
              <path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/>
            </svg>
          </button>
        </div>
      </div>

      <style>
        .audio-section { display: flex; justify-content: center; align-items: center; padding: 20px 0; width: 100%; }
        .recording-controls { display: flex; justify-content: center; align-items: center; }
        #recordingWidget-button-toggle {
          width: 90px; height: 90px; border-radius: 50%; border: none; cursor: pointer;
          background-color: #3974CB; color: white; display: flex; align-items: center; justify-content: center; font-size: 38px;
          transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1); box-shadow: 0 4px 10px rgba(0,0,0,0.25);
        }
        #recordingWidget-button-toggle:hover { background-color: #4B9AE9; transform: scale(1.05); box-shadow: 0 6px 12px rgba(0,0,0,0.3); }
        #recordingWidget-button-toggle.is-recording { background-color: #f44336; animation: pulse-animation 1.5s infinite; }
        #recordingWidget-button-toggle svg { pointer-events: none; transition: transform 0.3s ease-in-out; }
        @keyframes pulse-animation {
          0% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0.7); }
          70% { box-shadow: 0 0 0 25px rgba(244, 67, 54, 0); }
          100% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0); }
        }
      </style>

      <script>
        if (!window.recordingWidgetGlobals) {
          window.recordingWidgetGlobals = true;

          const logger = window.createLogger('RecordingWidget');

          // --- FACT-BASED WORKAROUND FOR iOS PWA STALE PERMISSIONS BUG ---
          // This logic detects if this is a subsequent launch of the PWA and forces a reload
          // to fix the broken media stream state in WebKit. This is the current industry
          // standard solution for this specific, well-documented iOS bug.
          const hasInitializedKey = 'hasInitializedAudioSession';
          if (sessionStorage.getItem(hasInitializedKey)) {
            // This is a subsequent launch (e.g., re-opening the PWA). The media state is likely stale.
            logger.warn("Subsequent PWA launch detected. Forcing a one-time reload to fix potential stale media permissions on iOS.");
            // We remove the key BEFORE reloading, so the reloaded session is treated as the "first" one.
            sessionStorage.removeItem(hasInitializedKey);
            window.location.reload();
          } else {
            // This is the first launch of the session. Set the flag.
            logger.log("First launch of the session. Setting initialization flag.");
            sessionStorage.setItem(hasInitializedKey, 'true');
          }
          // --- END OF WORKAROUND ---

          let stream;
          let audioContext;
          let workletNode;
          let isRecording = false;
          let audioBuffer = [];
          let bufferLength = 0;

          const toggleButton = document.getElementById('recordingWidget-button-toggle');
          if (!toggleButton) {
            logger.error("Critical: Toggle button not found. Widget will not function.");
          } else {
            logger.log("Recording widget initialized.");

            const checkmarkIcon = `<svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="bi bi-check" viewBox="0 0 16 16"><path d="M10.97 4.97a.75.75 0 0 1 1.07 1.05l-3.99 4.99a.75.75 0 0 1-1.08.02L4.324 8.384a.75.75 0 1 1 1.06-1.06l2.094 2.093 3.473-4.425a.267.267 0 0 1 .02-.022z"/></svg>`;
            const micIcon = `<svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" viewBox="0 0 16 16"><path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z"/><path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/></svg>`;
            const workletProcessorString = `
                class RecorderProcessor extends AudioWorkletProcessor {
                  process(inputs) {
                    if (inputs[0][0]) this.port.postMessage(inputs[0][0].slice(0));
                    return true;
                  }
                }
                registerProcessor('recorder-processor', RecorderProcessor);
              `;

            const initializeAndResumeAudioContext = async () => {
              if (audioContext && audioContext.state === 'running') return true;
              try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') {
                  await audioContext.resume();
                }
                return audioContext.state === 'running';
              } catch (error) {
                logger.error("Failed to initialize or resume AudioContext:", error);
                return false;
              }
            };

            const cleanup = () => {
              isRecording = false;
              if (workletNode) workletNode.disconnect();
              if (stream) stream.getTracks().forEach(track => track.stop());
              resetButtonUI();
              logger.log("Recording resources cleaned up.");
            };

            const startRecording = async () => {
              if (isRecording) return;
              logger.log("Attempting to start recording...");

              if (!(await initializeAndResumeAudioContext())) {
                logger.error("Could not start recording: AudioContext is not running.");
                return;
              }

              try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                logger.log("Microphone stream acquired.");

                const blob = new Blob([workletProcessorString], { type: 'application/javascript' });
                await audioContext.audioWorklet.addModule(URL.createObjectURL(blob));

                const source = audioContext.createMediaStreamSource(stream);
                workletNode = new AudioWorkletNode(audioContext, 'recorder-processor');

                audioBuffer = [];
                bufferLength = 0;

                workletNode.port.onmessage = (event) => {
                  if (isRecording) {
                    audioBuffer.push(event.data);
                    bufferLength += event.data.length;
                  }
                };
                source.connect(workletNode).connect(audioContext.destination);

                isRecording = true;
                toggleButton.innerHTML = checkmarkIcon;
                toggleButton.classList.add('is-recording');
                logger.log("Recording is now active.");

              } catch (error) {
                logger.error("Error during startRecording (after context activation):", error);
                anvil.call(toggleButton, 'show_error', `Microphone access error: ${error.name} - ${error.message}`);
                cleanup();
              }
            };

            const stopRecording = () => {
              if (!isRecording) return;
              logger.log("Stopping recording...");

              const finalBuffer = new Float32Array(bufferLength);
              let offset = 0;
              for (const buffer of audioBuffer) {
                finalBuffer.set(buffer, offset);
                offset += buffer.length;
              }

              const wavBlob = encodeWAV(finalBuffer, audioContext.sampleRate);
              if (wavBlob.size > 44) {
                anvil.call(toggleButton, 'handle_js_recording_complete', wavBlob, 'audio/wav');
              } else {
                logger.warn("Recording stopped with an empty audio buffer.");
              }
              cleanup();
            };

            const resetButtonUI = () => {
              toggleButton.innerHTML = micIcon;
              toggleButton.classList.remove('is-recording');
            };

            toggleButton.addEventListener('click', () => {
              if (isRecording) {
                stopRecording();
              } else {
                startRecording();
              }
            });

            function encodeWAV(samples, sampleRate) {
              const buffer = new ArrayBuffer(44 + samples.length * 2);
              const view = new DataView(buffer);
              const writeString = (o, s) => { for (let i = 0; i < s.length; i++) view.setUint8(o + i, s.charCodeAt(i)); };
              const floatTo16BitPCM = (out, off, inp) => { for (let i = 0; i < inp.length; i++, off+=2) { const s = Math.max(-1, Math.min(1, inp[i])); out.setInt16(off, s < 0 ? s * 0x8000 : s * 0x7FFF, true); } };
                                                                                                                                                                    writeString(0, 'RIFF'); view.setUint32(4, 36 + samples.length * 2, true);
                                                                                                                                                                    writeString(8, 'WAVE'); writeString(12, 'fmt '); view.setUint32(16, 16, true);
                                                                                                                                                                    view.setUint16(20, 1, true); view.setUint16(22, 1, true);
                                                                                                                                                                    view.setUint32(24, sampleRate, true); view.setUint32(28, sampleRate * 2, true);
                                                                                                                                                                    view.setUint16(32, 2, true); view.setUint16(34, 16, true);
                                                                                                                                                                    writeString(36, 'data'); view.setUint32(40, samples.length * 2, true);
                                                                                                                                                                    floatTo16BitPCM(view, 44, samples);
                                                                                                                                                                    return new Blob([view], { type: 'audio/wav' });
                                                                                                                                                                    }
                                                                                                                                                                    }
                                                                                                                                                                    }
                                                                                                                                                                    </script>
  type: HtmlTemplate
custom_component: true
events:
- default_event: true
  name: recording_complete
  parameters:
  - {name: audio_blob}
is_package: true
properties: []
