components: []
container:
  properties:
    html: |-
      <div class="audio-section">
        <div class="recording-controls" id="recordingMode">
          <button id="recordingWidget-button-toggle" title="Start Recording">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" viewBox="0 0 16 16">
              <path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z"/>
              <path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/>
            </svg>
          </button>
        </div>
      </div>

      <style>
        .audio-section { display: flex; justify-content: center; align-items: center; padding: 20px 0; width: 100%; }
        .recording-controls { display: flex; justify-content: center; align-items: center; }
        #recordingWidget-button-toggle {
          width: 90px; height: 90px; border-radius: 50%; border: none; cursor: pointer;
          background-color: #3974CB; color: white; display: flex; align-items: center; justify-content: center; font-size: 38px;
          transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1); box-shadow: 0 4px 10px rgba(0,0,0,0.25);
        }
        #recordingWidget-button-toggle:hover { background-color: #4B9AE9; transform: scale(1.05); box-shadow: 0 6px 12px rgba(0,0,0,0.3); }
        #recordingWidget-button-toggle.is-ready { background-color: #4CAF50; /* Green to indicate ready */ }
        #recordingWidget-button-toggle.is-recording { background-color: #f44336; animation: pulse-animation 1.5s infinite; }
        #recordingWidget-button-toggle svg { pointer-events: none; transition: transform 0.3s ease-in-out; }
        @keyframes pulse-animation {
          0% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0.7); }
          70% { box-shadow: 0 0 0 25px rgba(244, 67, 54, 0); }
          100% { box-shadow: 0 0 0 0 rgba(244, 67, 54, 0); }
        }
      </style>

      <script>
        if (!window.recordingWidgetGlobals) {
          window.recordingWidgetGlobals = true;

          const logger = window.createLogger('RecordingWidget');
          let stream;
          let audioContext;
          let workletNode;
          let isRecording = false;
          let isAudioSystemReady = false; // NEW state flag
          let audioBuffer = [];
          let bufferLength = 0;

          const toggleButton = document.getElementById('recordingWidget-button-toggle');
          if (!toggleButton) {
            logger.error("Critical: Toggle button not found.");
          } else {
            logger.log("Recording widget initialized.");

            const checkmarkIcon = `<svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="bi bi-check" viewBox="0 0 16 16"><path d="M10.97 4.97a.75.75 0 0 1 1.07 1.05l-3.99 4.99a.75.75 0 0 1-1.08.02L4.324 8.384a.75.75 0 1 1 1.06-1.06l2.094 2.093 3.473-4.425a.267.267 0 0 1 .02-.022z"/></svg>`;
            const micIcon = `<svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" viewBox="0 0 16 16"><path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z"/><path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/></svg>`;
            const workletProcessorString = `
                class RecorderProcessor extends AudioWorkletProcessor {
                  process(inputs) { if (inputs[0][0]) this.port.postMessage(inputs[0][0].slice(0)); return true; }
                }
                registerProcessor('recorder-processor', RecorderProcessor);
              `;

            const initializeAudioSystem = async () => {
              if (isAudioSystemReady) return true;
              logger.log("PRIMING STAGE: Initializing audio system for the first time...");
              try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') {
                  logger.log("PRIMING STAGE: AudioContext is suspended. Resuming now...");
                  await audioContext.resume();
                }
                isAudioSystemReady = (audioContext.state === 'running');
                if (isAudioSystemReady) {
                  logger.log("PRIMING STAGE: SUCCESS. AudioContext is now running. System is ready.");
                  toggleButton.classList.add('is-ready');
                  toggleButton.title = "Ready. Click to start recording.";
                }
                return isAudioSystemReady;
              } catch (error) {
                logger.error("PRIMING STAGE: FAILED to initialize AudioContext:", error);
                anvil.call(toggleButton, 'show_error', `Audio system failed: ${error.message}`);
                return false;
              }
            };

            const cleanup = () => {
              isRecording = false;
              if (workletNode) workletNode.disconnect();
              if (stream) stream.getTracks().forEach(track => track.stop());
              resetButtonUI();
            };

            const startRecording = async () => {
              if (isRecording || !isAudioSystemReady) return;
              logger.log("RECORDING STAGE: Attempting to start recording...");

              try {
                stream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                logger.log("RECORDING STAGE: Microphone stream acquired.");

                const blob = new Blob([workletProcessorString], { type: 'application/javascript' });
                await audioContext.audioWorklet.addModule(URL.createObjectURL(blob));

                const source = audioContext.createMediaStreamSource(stream);
                workletNode = new AudioWorkletNode(audioContext, 'recorder-processor');

                audioBuffer = [];
                bufferLength = 0;
                workletNode.port.onmessage = (event) => {
                  if (isRecording) {
                    audioBuffer.push(event.data);
                    bufferLength += event.data.length;
                  }
                };
                source.connect(workletNode).connect(audioContext.destination);

                isRecording = true;
                toggleButton.classList.remove('is-ready');
                toggleButton.classList.add('is-recording');
                toggleButton.title = "Stop recording";
                toggleButton.innerHTML = checkmarkIcon;
                logger.log("RECORDING STAGE: SUCCESS. Recording is now active.");

              } catch (error) {
                logger.error("RECORDING STAGE: FAILED during media setup:", error);
                anvil.call(toggleButton, 'show_error', `Microphone access error: ${error.name}`);
                cleanup();
              }
            };

            const stopRecording = () => {
              if (!isRecording) return;
              logger.log("Stopping recording...");

              const finalBuffer = new Float32Array(bufferLength);
              let offset = 0;
              for (const buffer of audioBuffer) finalBuffer.set(buffer, offset), offset += buffer.length;

              const wavBlob = encodeWAV(finalBuffer, audioContext.sampleRate);
              if (wavBlob.size > 44) {
                anvil.call(toggleButton, 'handle_js_recording_complete', wavBlob, 'audio/wav');
              } else {
                logger.warn("Stopped with an empty audio buffer.");
              }
              cleanup();
            };

            const resetButtonUI = () => {
              toggleButton.innerHTML = micIcon;
              toggleButton.classList.remove('is-recording');
              toggleButton.classList.remove('is-ready');
              toggleButton.title = "Start Recording";
            };

            toggleButton.addEventListener('click', async () => {
              logger.log("Button clicked.");
              if (!isAudioSystemReady) {
                await initializeAudioSystem();
              } else if (isRecording) {
                stopRecording();
              } else {
                startRecording();
              }
            });

            function encodeWAV(samples, sampleRate) {
              const buffer = new ArrayBuffer(44 + samples.length * 2);
              const view = new DataView(buffer);
              const writeString = (o, s) => { for (let i = 0; i < s.length; i++) view.setUint8(o + i, s.charCodeAt(i)); };
              const floatTo16BitPCM = (out, off, inp) => { for (let i = 0; i < inp.length; i++, off+=2) { const s = Math.max(-1, Math.min(1, inp[i])); out.setInt16(off, s < 0 ? s * 0x8000 : s * 0x7FFF, true); } };
              writeString(0, 'RIFF'); view.setUint32(4, 36 + samples.length * 2, true);
              writeString(8, 'WAVE'); writeString(12, 'fmt '); view.setUint32(16, 16, true);
              view.setUint16(20, 1, true); view.setUint16(22, 1, true);
              view.setUint32(24, sampleRate, true); view.setUint32(28, sampleRate * 2, true);
              view.setUint16(32, 2, true); view.setUint16(34, 16, true);
              writeString(36, 'data'); view.setUint32(40, samples.length * 2, true);
              floatTo16BitPCM(view, 44, samples);
              return new Blob([view], { type: 'audio/wav' });
            }
          }
        }
      </script>
  type: HtmlTemplate
custom_component: true
events:
- default_event: true
  name: recording_complete
  parameters:
  - {name: audio_blob}
is_package: true
properties: []
